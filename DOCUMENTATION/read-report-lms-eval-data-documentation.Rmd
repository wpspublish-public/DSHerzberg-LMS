---
title: <font size="6">Read and report course evaluation data from LMS</font>
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

#### Overview

This is a method for reading in output from WPS LMS system, cleaning up and reformatting the data, and producing a report of frequency counts for the course evaluations.

One of the key elements of processing is to handle columns that include super-ordinate questions, sub-ordinate questions, and responses. Here is an example of one such column:

```
   `General Live Webinar Experience`                                                                   

 Overall educational experience: 3, Accessibility of platforms/materials: 3, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 4, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 4, Technical quality (e.g.…
 Overall educational experience: 3, Accessibility of platforms/materials: 1, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
 Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
Overall educational experience: 5, Accessibility of platforms/materials: 5, Technical quality (e.g.…
```
The column name, `General Live Webinar Experience` is a super-ordinate question. The row values going down the column contain both the sub-ordinate questions (e.g., `Overall educational experience`, `Accessibility of platforms/materials`, etc.), and the numerical responses to those sub-ordinate questions. This represents a classic "untidy" data input, and this code cleans it up by creating separate columns for each super- and sub-ordinate question pair, with the rows containing numerical responses by person.

###### RUNNABLE CODE
```{r script, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(xlsx))

input <-
  suppressMessages(read_csv(here(
    "INPUT-FILES/summary-evaluation-data.csv"
  )))

names_input <- names(input)
token_super_sub_first_col <- "General Live Webinar Experience"
token_super_sub_last_col <- "Usefulness of Content"
token_addl_cols_for_freq_counts <- c("Would you recommend this CE program to others?", 
                                     "In general, what format do you prefer for webinars? Choose all that apply:", 
                                     "In general, what time of day do you prefer to begin a live webinar?", 
                                     "How did you learn about this CE program?", 
                                     "What is your highest academic degree?",
                                     "What is your field of work?", 
                                     "I certify that I am the person who attended the live webinar and completed this evaluation.")
token_lhs_intact_cols <- c("First Name", "Last Name", "Email", "Credits")
token_rhs_text_cols <- c("How will you use the knowledge gained from this course within your practice?",
                         "If you selected Other, please specify:",
                         str_c("Please share any other feedback you have, including suggestions ",
                         "for future continuing education you’d like to see available through WPS, ", 
                         "such as specific topics for live workshops, webinars, or independent study opportunities:"),
                         "If you selected Other, please specify:_1")
token_split_destination_cols <- c("q1", "r1", "q2", "r2", "q3", "r3", "q4", "r4", "q5", "r5")
token_split_regex <- ":|(?<=[[:digit:]]),"

df_super_sub_cols <- input %>% 
  select(all_of(token_super_sub_first_col):all_of(token_super_sub_last_col))

date_col <- input %>% 
  select(Completed) %>% 
  transmute(Completed = lubridate::mdy_hm(Completed))

lhs_cols <- input %>% 
  select(all_of(token_lhs_intact_cols)) %>% 
  mutate(across(where(is.logical), as.character))

rhs_num_cols <- input %>% 
  select(all_of(token_addl_cols_for_freq_counts))

rhs_text_cols <- input %>% 
  select(all_of(token_rhs_text_cols))

q_name <- str_c(str_replace_all(names(df_super_sub_cols), " ", "_"), ":")

list_super_sub_cols <- map(
  names(df_super_sub_cols),
  ~ df_super_sub_cols %>%
    select(!!sym(.x)) %>%
    separate(
      !!sym(.x),
      all_of(token_split_destination_cols),
      token_split_regex,
      remove = TRUE
    ) %>% 
    janitor::remove_empty("cols")
)

list_r_cols <- map(list_super_sub_cols,
                   ~ .x %>%
                     select(contains("r")) %>%
                     mutate(across(
                       everything(),
                       ~ str_replace(., " ", "") %>%
                         as.integer()
                     )))

list_sub_q_names <- map(
  list_super_sub_cols,
  ~ .x %>%
    select(contains("q")) %>%
    filter(row_number() == 1) %>%
    as.character() %>%
    str_replace_all(" ", "_")
)

list_col_names <- map2(list_sub_q_names,
                       q_name,
                       ~
                         str_c(.y, .x, sep = "_") %>%
                         str_replace(., "__", "_"))

named_super_sub_r_cols <- map2(list_r_cols,  list_col_names,
                                    ~ .x %>%
                                      set_names(.y)) %>% 
  bind_cols()

output <- bind_cols(
  lhs_cols,
  date_col,
  named_super_sub_r_cols,
  rhs_cols
)

write_csv(output,
          here("OUTPUT-FILES/lms-output.csv"),
          na = "")

school_psych <- output %>% 
  filter(`What is your field of work?` == "School Psychology") %>% 
  select(all_of(names(named_super_sub_r_cols))) %>% 
  pivot_longer(everything(), names_to = 'item', values_to = 'value') %>% 
  count(item, value) %>% 
  group_by(item) %>% 
  complete(value = 1:5) %>% 
  arrange(desc(value), .by_group = TRUE) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(total = sum(n),
         total_pct = round(100*(n/total), 1),
         valid_pct = round(100*(n/total), 1),
         csum = cumsum(n),
         valid_cum_pct = round(100*(csum/total), 1),
  ) %>% 
  separate(
    item,
    c("super_q", "sub_q"),
    ":_",
    remove = TRUE
  ) %>% mutate(
    super_q = case_when(
      lag(super_q) == super_q  ~ NA_character_,
      TRUE ~ super_q
    ),
    sub_q = case_when(
      lag(sub_q) == sub_q  ~ NA_character_,
      TRUE ~ sub_q
    ),
    label = case_when(
      value == 5 ~ "excellent",
      value == 4 ~ "above average",
      value == 3 ~ "average",
      value == 2 ~ "below average",
      value == 1 ~ "poor",
      TRUE ~ NA_character_
    ),
    across(c(total_pct, valid_pct, valid_cum_pct), ~ format(., digits = 1, nsmall = 1))
    ) %>%
  select(super_q, sub_q, value, label, n, total_pct, valid_pct, valid_cum_pct, total) %>% 
  rename(freq = n) %>% 
  as.data.frame() %>%
  mutate(across(everything(), ~ replace_na(., ""))) %>% 
  write.xlsx(
    here("OUTPUT-FILES/school-psych-report.xlsx"),
    sheetName = "school_psych",
    row.names = FALSE,
    append = FALSE
  )
```

<br>

###### COMMENTED SNIPPETS
Load libraries and read input data.
```{r script, echo = 1:8, eval = FALSE}
```
Initialize tokens representing job-specific elements. These tokens are of three types:

* Tokens that allow subsequent code to segregate blocks of contiguous columns. These tokens either identify the boundary columns of these contiguous blocks (e.g, `token_super_sub_first_col`), or they contain the names of all of the columns in a block (e.g., `token_lhs_intact_cols`).
* `token_split_destination_cols`, which holds the names of interim destination columns for the super/sub-ordinate question text (names contain `q`) and numerical responses (names contain `r`). The token is a character vector containing the destination column names in question-response pairs (e.g., `c("q1", "r1", "q2", "r2", "q3", "r3", "q4", "r4", "q5", "r5")`). 
   + This vector should be set up to contain as many pairs as are required by the super-ordinate question that contains the MOST subordinate questions. 
   + Super-ordinate questions with fewer subordinate questions are handled automatically by the code.
* `token_split_regex`, which contains the regular expression (here `":|(?<=[[:digit:]]),"`) that allows R to segregate the question text and numerical responses within each cell, so that these components can be sent to separate destination columns.
   + A _regular expression_ describes a text element to search for and match in data. In R, regular expressions are written as strings enclosed in double quotes.
   + `:|(?<=[[:digit:]]),` contains two elements separated by `|`, meaning that it will match _either_ element.The LHS element is a colon `:`.
   + The RHS contains two parts: an expression `<=[[:digit:]]` enclosed in specialized parentheses `(?...)`, and a comma `,`. The comma is the character to match, and the specialized parenthetic expression denotes a _look-around_, which defines a position where the comma must appear in order to yield a match.
     + Within the specialized parentheses, we have `[[:digit:]]`, a character class that matches any digit from `0` to `9`. To its left is `<=`, which in this context is the "preceded by" look-around operator.
     + Thus, `(?<=[[:digit:]])` is an instruction to look for a match to the right of a digit. Importantly, however, it does not, itself, match any text. It rather identifies a location to search.
  + Taken as a whole, then, `":|(?<=[[:digit:]]),"` tells R to match _either_ a colon `:` _or_ a comma immediately preceded by a digit (i.e., in `3,`, R matches the `,`, but not the `3`). By matching only commas preceded by digits, we avoid matching other commas that may exist within a string that constitutes the text of a question.
  + Earlier, we provided an example of cells containing a mixture of question text and numerical responses (e.g., `Overall educational experience: 3, Accessibility of...`). Note that the regular expression in `token_split_regex` is set up to match the two characters, `:` and `,`, that mark the boundaries between question text and numerical responses. And, as noted above, we match only the commas that are located in boundary positions, not commas that may be located within the text of a question.
```{r script, echo = 10:28, eval = FALSE}
```
We now use these tokens to segregate and process blocks of columns for downstream processing. Some details to note:

* Within `dplyr::select()`, we can use tokens (e.g., `token_super_sub_first_col`, `token_super_sub_last_col`) to designate the first and last columns in a block. Because these tokens are character vectors, within `select()` we need to wrap them in the tidyselect helper `all_of()`.
* We transform completion dates in the `Completed` column into a standard UTC format with `lubridate::mdy_hm()`, using the version of this function that matches the input format of the dates. We use `dplyr::transmute()` for this operation, because it discards the input column as it creates the new, properly formatted `Completed` column.
* Some of the input columns are logical vectors, a format that is not needed in the output.
```{r script, echo = 30:47, eval = FALSE}
```
