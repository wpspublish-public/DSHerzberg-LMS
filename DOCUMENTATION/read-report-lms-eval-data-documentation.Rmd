---
title: <font size="6">Read and report course evaluation data from LMS</font>
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

#### Overview

This is a method for reading output from WPS LMS system, cleaning up and reformatting the data, and producing a report of frequency counts for the course evaluations.

A key element of cleanup is handling columns that contain super-ordinate questions, sub-ordinate questions, and responses. Here is an example of one such column:

```
`Access/Setting/Overall Experience`                               

Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 4 | Above average, Accessibility of platforms/ma…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
Overall educational experience: 4 | Above average, Accessibility of platforms/ma…
Overall educational experience: 3 | Average, Accessibility of platforms/material…
Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…
```
The column name, `Access/Setting/Overall Experience` is a super-ordinate question. Going down the column, the cells contain the sub-ordinate questions (e.g., `Overall educational experience`, `Accessibility of platforms/materials`, etc.), the numerical responses to those sub-ordinate questions, and the text labels corresponding to each numerical response (e.g., `5 | Excellent`). This represents a classic "untidy" data input. The cleanup process creates separate columns for each super- and sub-ordinate question pair, with the rows containing _only_ the numerical responses by person (i.e, without the text labels in the input).

#### Initial data preparation and cleanup

###### RUNNABLE CODE
```{r prep, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(writexl))

input <-
  suppressMessages(read_csv(here(
    "INPUT-FILES/input-survey-ados2-workshop-2021-04-16.csv"
  )))

names_input <- names(input)
token_super_sub_first_col <- "Access/Setting/Overall Experience"
token_super_sub_last_col <- "Usefulness of Content"
token_addl_cols_for_freq_counts <- c("Would you recommend this CE program to others?", 
                                     "In general, what format do you prefer for webinars?", 
                                     "In general, what time of day do you prefer to begin a live webinar?", 
                                     "How did you learn about this CE program?", 
                                     "What is your highest academic degree?",
                                     "What is your field of work?", 
                                     "I certify that I am the person who attended the live webinar and completed this evaluation.")
token_lhs_intact_cols <- c("First Name", "Last Name", "Email", "Credits")
token_rhs_text_cols <- c("How will you use the knowledge gained from this course within your practice?",
                         "If you selected Other, please specify:",
                         str_c("Please share any other feedback you have, including suggestions ",
                         "for future continuing education you’d like to see available through WPS, ", 
                         "such as specific topics for live workshops, webinars, or independent study opportunities:"),
                         "If you selected Other, please specify:_1")
token_split_destination_cols <- c("q1", "r1", "q2", "r2", "q3", "r3", "q4", "r4", "q5", "r5")
token_split_regex <- ":|(?<=[[:digit:]]),"

df_super_sub_cols <- input %>% 
  select(all_of(token_super_sub_first_col):all_of(token_super_sub_last_col)) %>% 
  mutate(across(everything(),
                ~ str_replace_all(
                  .,
                  c(
                    " [|] Excellent" = "",
                    " [|] Above average" = "",
                    " [|] Average" = "",
                    " [|] Below average" = "",
                    " [|] Poor" = "",
                    " [|] Strongly agree" = "",
                    " [|] Agree" = "",
                    " [|] Neutral" = "",
                    " [|] Disagree" = "",
                    " [|] Strongly disagree" = "",
                    " [|] Extremely useful" = "",
                    " [|] A good deal useful" = "",
                    " [|] Somewhat useful" = "",
                    " [|] A little useful" = "",
                    " [|] Not useful" = "",
                    " [|] A great deal" = "",
                    " [|] More than average" = "",
                    " [|] Average" = "",
                    " [|] Less than average" = "",
                    " [|] Very little" = ""
                  )
                )))

date_col <- input %>% 
  select(Completed) %>% 
  transmute(Completed = lubridate::mdy_hm(Completed))

lhs_cols <- input %>% 
  select(all_of(token_lhs_intact_cols)) %>% 
  mutate(across(where(is.logical), as.character))

rhs_num_cols <- input %>% 
  select(all_of(token_addl_cols_for_freq_counts))

rhs_text_cols <- input %>% 
  select(all_of(token_rhs_text_cols))

recommend_CE <- tibble(
  item = rep("Would you recommend this CE program to others?", 2),
  value = 1:2,
  label = c("Yes", "No")
)

webinar_format <- tibble(
  item = rep(
    str_c(
      "In general, what format do you prefer ",
      "for webinars?"
    ),
    6
  ),
  value = 1:6,
  label = c(
    "Single half-day (3–4 hours/day)",
    "Single full-day (5–6 hours/day)",
    "Multiday (half-days)",
    "Multiday (full-days)",
    "Pre-recorded at own pace (no live instruction)",
    "Blended instruction (live webinar combined with independent study)"
  )
)

webinar_time <- tibble(
  item = rep("In general, what time of day do you prefer to begin a live webinar?",
             3),
  value = 1:3,
  label = c("Morning",
            "Afternoon",
            "Evening")
)

learn_CE <- tibble(
  item = rep("How did you learn about this CE program?",
             7),
  value = 1:7,
  label = c(
    "WPS website",
    "WPS catalog/print advertisement",
    "Direct email from WPS",
    "Social media (e.g., Facebook)",
    "Supervisor",
    "Colleague",
    "Other (answer in next question)"
  )
)

highest_degree <- tibble(
  item = rep("What is your highest academic degree?",
             5),
  value = 1:5,
  label = c(
    "Doctorate",
    "Master’s (MSW, MS, MA)",
    "Bachelor’s (BS, BA)",
    "Associates",
    "No college degree"
  )
)

field_work <- tibble(
  item = rep("What is your field of work?",
             14),
  value = 1:14,
  label = c(
    "Applied Behavior Analysis (ABA; BABCP)",
    "Clinical Psychology",
    "Counseling",
    "Educational Diagnostician/Psychometrist",
    "Medicine",
    "Neuropsychology",
    "Occupational Therapy",
    "Physical Therapy",
    "Psychiatry",
    "School Psychology",
    "Social Work",
    "Special Education",
    "Speech–Language Pathology/Audiology",
    "Other (answer in next question)"
  )
)

certify_attend <- tibble(
  item =
    str_c(
      "I certify that I am the person who attended ",
      "the live webinar and completed this evaluation."
    ),
  value = 1,
  label = "Yes"
)

item_value_label_map <- bind_rows(
  recommend_CE,
  webinar_format,
  webinar_time,
  learn_CE,
  highest_degree,
  field_work,
  certify_attend
)
```

<br>

###### COMMENTED SNIPPETS
Load libraries and read input data.
```{r prep, echo = 1:8, eval = FALSE}
```
Initialize tokens representing job-specific elements. These tokens are of three types:

* Tokens that allow subsequent code to segregate blocks of contiguous columns. These tokens either identify the boundary columns of these contiguous blocks (e.g, `token_super_sub_first_col`), or they contain the names of all of the columns in a block (e.g., `token_lhs_intact_cols`).
* `token_split_destination_cols`, which holds the names of interim destination columns for the super/sub-ordinate question text (names contain `q`) and numerical responses (names contain `r`). The token is a character vector containing the destination column names in question-response pairs (e.g., `c("q1", "r1", "q2", "r2", "q3", "r3", "q4", "r4", "q5", "r5")`). 
   + This vector should be set up to contain as many pairs as are required by the super-ordinate question that contains the MOST subordinate questions. 
   + Super-ordinate questions with fewer subordinate questions are handled automatically by the code.
* `token_split_regex`, which holds the regular expression (here `":|(?<=[[:digit:]]),"`) that allows R to segregate the question text and numerical responses within each cell, so that these components can be sent to separate destination columns.
   + A _regular expression_ describes a text element to search for and match in data. In R, regular expressions are written as strings enclosed in double quotes.
   + `:|(?<=[[:digit:]]),` contains two elements separated by `|`, meaning that it will match _either_ element.The LHS element is a colon `:`.
   + The RHS contains two parts: an expression `<=[[:digit:]]` enclosed in specialized parentheses `(?...)`, and a comma `,`. The comma is the character to match, and the specialized parenthetic expression denotes a _look-around_, which defines a position where the comma must appear in order to yield a match.
     + Within the specialized parentheses, we have `[[:digit:]]`, a character class that matches any digit from `0` to `9`. To its left is `<=`, which in this context is the "preceded by" look-around operator.
     + Thus, `(?<=[[:digit:]])` is an instruction to look for a match to the right of a digit. Importantly, however, it does not, itself, match any text. It rather identifies a location to search.
  + Taken as a whole, then, `":|(?<=[[:digit:]]),"` tells R to match _either_ a colon `:` _or_ a comma immediately preceded by a digit (i.e., in `3,`, R matches the `,`, but not the `3`). By matching only commas preceded by digits, we avoid matching other commas that may exist within a string that constitutes the text of a question.
  + Earlier, we provided an example of cells containing a mixture of question text and numerical responses (e.g., `Overall educational experience: 5 | Excellent, Accessibility of platforms/materi…`). Note that the regular expression in `token_split_regex` is set up to match the two characters, `:` and `,`, that mark the boundaries between question text and numerical responses. And, as noted above, we match only the commas that are located in boundary positions, not commas that may be located within the contiguous text of a question.
```{r prep, echo = 10:28, eval = FALSE}
```
We now use these tokens to segregate and process blocks of columns for downstream processing. Some details to note:

* Within `dplyr::select()`, we can use tokens (e.g., `token_super_sub_first_col`, `token_super_sub_last_col`) to designate the first and last columns in a block. Because these tokens are character vectors, we need to wrap them in the tidyselect helper `all_of()` when we pass them to a `dplyr` selecting function.
* For data cleanup, we prefer elegant, generalizeable solutions, but for expediency's sake we sometimes make do with hard-coded work-arounds. The snippet below contains an example of such a work-around; we use `stringr::str_replace_all()` to strip out all different versions of the unneeded value labels for the sub-ordinate question numerical responses. These versions are hard-coded (stated explicitly in the code) so they must be edited when the script is adapted to new projects. The desired recoding (or stripping, in which we replace a certain pattern with `""`) can be passed to `str_replace_all()` in the form of a vector of pattern-replacement pairs (e.g, `" [|] Excellent" = ""`).
* Note how, within `str_replace_all()`, the vertical pipe character is enclosed in straight brackets (e.g., `[|]`). Because the vertical pipe is a reserved character in R, it must be "escaped" when it is part of a search string in a text-replacement procedure. It turns out that enclosure in straight brackets is the most reliable way to "escape" the vertical pipe.
* We transform completion dates in the `Completed` column into a standard UTC format with `lubridate::mdy_hm()`, using the version of this function that matches the input format of the dates. We use `dplyr::transmute()` for this operation, because it discards the input column as it creates the new, properly formatted `Completed` column.
* Some of the input columns are logical vectors, a format that is not needed in the output. We transform these columns to character type with `mutate(across(where(is.logical), as.character))`. Here, `dplyr::across()` is used to identify the columns to be passed to `base::as.character`. When those columns are defined by a predicate function (e.g., `base::is.logical()`), that function must be wrapped in `tidyselect::where()`, which returns all columns for which predicate function returns `TRUE`.
```{r prep, echo = 30:71, eval = FALSE}
```
The columns designated by `token_addl_cols_for_freq_counts` are questions that each have a unique, finite set of numerically coded response choices. In the raw input, the cells of these columns contain the text value labels for these response choices, instead of the numerical codes needed for the output. Because each question has its own response options, the recoding instructions must be hard-coded into the script, as a lookup table that can be used downstream to replace text value labels with numerical codes.

To create the required lookup table, we use `tibble::tibble()` to initialize new data frames, one for each of the columns designated by `token_addl_cols_for_freq_counts`. Each new data frame has one row for each possible numerical response choice to that question (thus the data frames have differing lengths). All data frames have the same three columns:

* `item`: The question, as a string (e.g., `"Would you recommend this CE program to others?"`). We use `base::rep()` to repeat the string in each cell of the `item` column;
* `value`: a vector of integers expressing the range of numerical response choices (e.g., `1:2`);
* `label`: a character vector holding the value labels associated with each response choice (e.g., `c("Yes", "No")`).

The next snippet shows the procedure for generating the first two (`recommend_CE`, `webinar_format`) of these new data frames. 
```{r prep, echo = 73:96, eval = FALSE}
```
As a further example, we can examine `recommend_CE`:
```
item                                           value label

Would you recommend this CE program to others?     1 Yes  
Would you recommend this CE program to others?     2 No   
```
To create the lookup table required for downstream processing, we combine the new data frames into a single data frame `item_value_label_map`, stacking them one on top of the other with `dplyr::bind_rows()`.
```{r prep, echo = 167:175, eval = FALSE}
```

<br>

#### Format columns for frequency table output

###### RUNNABLE CODE

```{r format, eval = FALSE}
q_name <- str_c(str_replace_all(names(df_super_sub_cols), " ", "_"), ":")

list_super_sub_cols <- map(
  names(df_super_sub_cols),
  ~ df_super_sub_cols %>%
    select(!!sym(.x)) %>%
    separate(
      !!sym(.x),
      all_of(token_split_destination_cols),
      token_split_regex,
      remove = TRUE
    ) %>% 
    janitor::remove_empty("cols")
)

list_r_cols <- map(list_super_sub_cols,
                   ~ .x %>%
                     select(contains("r")) %>%
                     mutate(across(
                       everything(),
                       ~ str_replace(., " ", "") %>%
                         as.integer()
                     )))

list_sub_q_names <- map(
  list_super_sub_cols,
  ~ .x %>%
    select(contains("q")) %>%
    filter(row_number() == 1) %>%
    as.character() %>%
    str_replace_all(" ", "_") %>% 
    str_replace_all(
      c(
        "_Excellent,_" = "",
        "_Above average,_" = "",
        "_Average,_" = "",
        "_Below average,_" = "",
        "_Poor,_" = ""
      )
    ))

list_col_names <- map2(list_sub_q_names,
                       q_name,
                       ~
                         str_c(.y, .x, sep = "_") %>%
                         str_replace(., "__", "_"))

named_super_sub_r_cols <- map2(list_r_cols,  list_col_names,
                               ~ .x %>%
                                 set_names(.y)) %>%
  bind_cols()

output <- bind_cols(
  lhs_cols,
  date_col,
  named_super_sub_r_cols,
  rhs_num_cols,
  rhs_text_cols
)

write_csv(output,
          here("OUTPUT-FILES/lms-output-survey-ados2-workshop-2021-04-16.csv"),
          na = "")

school_psych <- output %>% 
  filter(`What is your field of work?` == "School Psychology") %>% 
  select(all_of(names(named_super_sub_r_cols))) %>% 
  pivot_longer(everything(), names_to = 'item', values_to = 'value') %>% 
  count(item, value) %>% 
  group_by(item) %>% 
  complete(value = 1:5) %>% 
  arrange(desc(value), .by_group = TRUE) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(total = sum(n),
         total_pct = round(100*(n/total), 1),
         valid_pct = round(100*(n/total), 1),
         csum = cumsum(n),
         valid_cum_pct = round(100*(csum/total), 1),
  ) %>% 
  separate(
    item,
    c("super_q", "sub_q"),
    ":_",
    remove = TRUE
  ) %>% mutate(
    super_q = case_when(
      lag(super_q) == super_q  ~ NA_character_,
      TRUE ~ super_q
    ),
    sub_q = case_when(
      lag(sub_q) == sub_q  ~ NA_character_,
      TRUE ~ sub_q
    ),
    label = case_when(
      value == 5 ~ "excellent",
      value == 4 ~ "above average",
      value == 3 ~ "average",
      value == 2 ~ "below average",
      value == 1 ~ "poor",
      TRUE ~ NA_character_
    ),
    across(c(total_pct, valid_pct, valid_cum_pct), ~ format(., digits = 1, nsmall = 1))
    ) %>%
  select(super_q, sub_q, value, label, n, total_pct, valid_pct, valid_cum_pct, total) %>% 
  rename(freq = n) %>% 
  as.data.frame() %>%
  mutate(across(everything(), ~ replace_na(., ""))) %>% 
  write.xlsx(
    here("OUTPUT-FILES/school-psych-report.xlsx"),
    sheetName = "school_psych",
    row.names = FALSE,
    append = FALSE
  )
```
<br>

###### COMMENTED SNIPPETS
To create the required frequency table output, we need to segregate and reformat the text of the super-ordinate questions. The strings that constitute those questions are the column names of `df_super_sub_cols`, a data frame generated earlier in this workflow. We now initialize a new vector `q_name` to hold the super-ordinate questions. We format the question text in two steps:

1. We pass `names(df_super_sub_cols)` to `str_replace_all()`, replacing blank spaces `" "` with underscores `"_"`.
2. We use `str_c()` to append a colon `":"` to each string that results from step 1.
```{r format, echo = 1, eval = FALSE}
```
The next step is to segregate the sub-ordinate questions, and the numerical responses to those questions. Currently, those two data elements are combined in the cells of `df_super_sub_cols`. 

The next snippet separates the questions from the responses, placing them in discrete destination columns. It does so with a mapping operation that iterates over the columns of `df_super_sub_cols`. As the `.x` argument to `map()`, we pass `names(df_super_sub_cols)` so that we can iteratively apply a function to each of these columns.

Recall that `df_super_sub_cols` is a data frame with a column for each super-ordinate question. Within those columns are the cells described above, in which the sub-ordinate questions and their numerical responses are combined in one long string, alternating as follows: first question, first response, second question, second response, and so forth.

Within `map()`, we call `tidyr::separate()` to divide up these long strings and send them to discrete destination columns. We pass four arguments to `separate()`:

* `!!sym(.x)` names the column within `df_super_sub_cols` whose cell contents will be split with `separate()`. `.x` designates the currently iterated column as the one to split. Because `.x` represents a character vector, its elements are themselves strings. To process these strings as column names within `separate()`, we must unquote them with the bang-bang `!!` operator, and coerce them to symbols with `rlang::sym()`.
* `all_of(token_split_destination_cols)` (argument label `into =` omitted) names the destination columns to be created by `separate()`. These names are held in `token_split_desinination_cols`, a character vector created in an earlier step. We use the `tidyselect` helper `all_of()` to specify that all elements of the vector are to be used as the names of the new destination columns.
* `token_split_regex` (argument label `sep =` omitted): a regular expression that evaluates to the positions or characters, within the long string, where `separate()` splits the text into substrings.^[`token_split_regex` was defined in detail earlier in this document]
* `remove = TRUE` means the input columns from `df_super_sub_cols` will not be included in the output, which at this point is a data frame with alternating question-response columns (e.g., `q1`, `r1`, `q2`, `r2`, and so forth).

Recall that `token_split_destination_cols` was set up earlier as a character vector containing destination column names in question-response pairs (e.g.,  `c("q1", "r1", "q2", "r2", "q3", "r3", "q4", "r4", "q5", "r5")`). Because `token_split_destination_cols` holds as many pairs as are required by the super-ordinate question that contains the MOST subordinate questions, some of the data frames generated at this point will have empty columns (i.e., columns whose cells are all `NA`). The reason for this is that the associated super-ordinate questions have fewer actual sub-ordinate question-response pairs than the maximum number denoted by `token_split_destination_cols`. For these situations, columns `q5` and `r5`, for example, will be empty. We drop these empty columns with `janitor::remove_empty("cols")`, thereby "right-sizing" the column count in each output data frame.

Because all of this processing happens within a call of `map()`, the output `list_super_sub_cols` is a list of data frames, one for each super-ordinate question. Each data frame holds, in discrete columns, the sub-ordinate questions and numerical responses corresponding to a single super-ordinate question.
```{r format, echo = 3:14, eval = FALSE}
```
In the data frames held by `list_super_sub_cols`, the numerical responses in the `r` columns are formatted as strings. The next code block coerces these strings to integers, so they can be processed into frequency tables in the final output.

We use `map()`, with `list_super_sub_cols` as the `.x` element, to transform one data frame at a time. We feed each data frame to `select(contains("r"))`, thus isolating only the columns containing the numerical responses. Using `mutate(across(everything))` we apply a function to all columns in the `.x` input. The cells of these columns contain numbers formatted as strings. We strip out white space with `str_replace(., " ", "")`, and coerce the result to integer with `base::as.integer()`. The code returns `list_r_cols`, a list of data frames holding the properly formatted numerical response columns for each super-ordinate question.
```{r format, echo = 16:23, eval = FALSE}
```
In the data frames held by `list_super_sub_cols`, the sub-ordinate question text exists as duplicate cell values in the `q` columns. We need to hold these strings in a vector so they can be used in the column names for the final output. As before, we `map()` over `list_super_sub_cols`, using the `.x` argument to feed one data from at a time to a series of functions that executes the required transformation.

We pass each data frame to `select(contains("q"))`, thus isolating only the columns containing the sub-ordinate question text. Because every cell of these columns contains identical strings, we capture only the first row with `filter(row_number() == 1)`, coercing this single row to a character vector with `as.character()`.

We then use two consecutive calls of `str_replace_all()` to clean up the question text. In the first call, we replace white space `" "` with underscore `"_"`. In the second call, we pass a vector of target-replacement pairs (e.g., `"_Excellent,_" = ""`) to `str_replace_all()`, allowing it to carry out multiple search-and-replace operations.

The enclosing call of `map()` returns a list of character vectors, each containing the cleaned-up sub-ordinate questions associated with a specific super-ordinate question.
```{r format, echo = 25:40, eval = FALSE}
```
In previous steps, we isolated and reformatted the text of the super- and sub-ordinate questions. The output requires separate columns for the numerical responses to each subordinate question. The names of these columns must include _both_ the sub-ordinate question _and_ its associated super-ordinate question. The next snippet merges pairs of super- and sub-ordinate questions into single strings that can be used as output column names.

To accomplish this we `map2()` over two objects of identical length: `list_sub_q_names`, a list containing (in this example) seven character vectors that hold the sub-ordinate question strings associated with seven super-ordinate questions; and `q_names`, a character vector holding the seven super-ordinate question strings. `map2()` iterates seven times over these objects, each time presenting a `.x` and a `.y` element for processing by the functions that follow. Within each iteration of `.x` and `.y`, `map2()` executes a nested iteration over the elements of `.x`; that is, over the vector of sub-ordinate questions that constitutes each element of `list_sub_q_names`. Within this nested iteration of `.x`, the value of the `.y` element (`q_name`, which holds the super-ordinate questions) recycles (is held constant), thus creating pairs of super-ordinate questions and their associated sub-ordinate questions.

These paired strings are concatenated with `str_c(.y, .x, sep = "_")`, which merges the two strings with an underscore separator. The concatenation unavoidably creates a double-underscore at one position in each string, which we strip out with `str_replace(., "__", "_"))`, where the `.` argument passes the output of the concatenating function.

`map()` thus returns `list_col_names`, which contains seven character vectors, one for each super-ordinate question. The elements of these vectors are the properly formatted, final output column names that combine each sub-ordinate question with its associated super-ordinate question.
```{r format, echo = 42:46, eval = FALSE}
```
At this stage we have separate objects holding the columns of numerical responses to the super-sub-ordinate questions (`list_r_cols`) and the required names for those columns (`list_col_names`). The next task is to combine those objects into a single data frame, attaching the names in `list_col_names` to the columns in `list_r_cols`.

We `map2()` over the two objects, with `.x` holding `list_r_cols`, and `.y` holding `list_col_names`. In each iteration, `.x` supplies a data frame of numerical responses to `set_names()`, which attaches the column names held in `.y`. `map2()` returns a list of data frames whose column names now meet output requirements. By passing this list to `bind_cols()` we return a single data frame, `named_super_sub_r_cols`, which contains all of the super-sub-ordinate question pairs and their numerical responses. 

In a second call of `bind_cols`, we join `named_super_sub_r_cols` with the other cleaned-up columns from the original input, creating `output`, a data frame that can be processed downstream to create frequency tables. We `write_csv(output)` to an external .csv file, replacing `NA` codes with blank space `""`.
```{r format, echo = 48:62, eval = FALSE}
```

<br>

#### Generate frequency table output

###### RUNNABLE CODE

```{r freq, eval = FALSE}
freq_table_super_sub_cols <- output %>% 
  select(all_of(names(named_super_sub_r_cols))) %>%  
  pivot_longer(everything(), names_to = 'item', values_to = 'value') %>% 
  count(item, value) %>% 
  group_by(item) %>% 
  complete(value = 1:5) %>% 
  arrange(desc(value), .by_group = TRUE) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(total = sum(n),
         total_pct = round(100*(n/total), 1),
         valid_pct = round(100*(n/total), 1),
         csum = cumsum(n),
         valid_cum_pct = round(100*(csum/total), 1),
  ) %>% 
  separate(
    item, 
    c("super_q", "sub_q"), 
    ":_", 
    remove = TRUE 
  ) %>% 
  mutate(
    label = case_when(
      (str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 5 ~ "Excellent",
      (str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 4 ~ "Above average",
      (str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 3 ~ "Average",
      (str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 2 ~ "Below average",
      (str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 1 ~ "Poor",
      str_detect(super_q, "Objectives") & value == 5 ~ "Strongly agree",
      str_detect(super_q, "Objectives") & value == 4 ~ "Agree",
      str_detect(super_q, "Objectives") & value == 3 ~ "Neutral",
      str_detect(super_q, "Objectives") & value == 2 ~ "Disagree",
      str_detect(super_q, "Objectives") & value == 1 ~ "Strongly disagree",
      str_detect(super_q, "Self-Evaluation") & value == 5 ~ "A great deal",
      str_detect(super_q, "Self-Evaluation") & value == 4 ~ "More than average",
      str_detect(super_q, "Self-Evaluation") & value == 3 ~ "Average",
      str_detect(super_q, "Self-Evaluation") & value == 2 ~ "Less than average",
      str_detect(super_q, "Self-Evaluation") & value == 1 ~ "Very little",
      str_detect(super_q, "Usefulness_of") & value == 5 ~ "Extremely useful",
      str_detect(super_q, "Usefulness_of") & value == 4 ~ "A good deal useful",
      str_detect(super_q, "Usefulness_of") & value == 3 ~ "Somewhat useful",
      str_detect(super_q, "Usefulness_of") & value == 2 ~ "A little useful",
      str_detect(super_q, "Usefulness_of") & value == 1 ~ "Not useful",
      TRUE ~ NA_character_
    )
  ) %>% 
  mutate(
    super_q = case_when(
      lag(super_q) == super_q  ~ NA_character_,
      TRUE ~ super_q
    ),
    sub_q = case_when(
      lag(sub_q) == sub_q  ~ NA_character_,
      TRUE ~ sub_q
    ),
    across(c(total_pct, valid_pct, valid_cum_pct), ~ format(., digits = 1, nsmall = 1)) 
  ) %>%
  select(super_q, sub_q, value, label, n, total_pct, valid_pct, valid_cum_pct, total) %>% 
  rename(freq = n) %>% 
  mutate(across(everything(), ~ replace_na(., "")))

freq_table_rhs_num_cols <- rhs_num_cols %>% 
  pivot_longer(everything(), names_to = 'item', values_to = 'value') %>% 
  count(item,value) %>% 
  rename(label = value) %>% 
  right_join(item_value_label_map, by = c("item", "label")) %>%
  relocate(value, .after = item) %>% 
  group_by(item) %>% 
  arrange(desc(value), .by_group = TRUE) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(total = sum(n),
         total_pct = round(100*(n/total), 1),
         valid_pct = round(100*(n/total), 1),
         csum = cumsum(n),
         valid_cum_pct = round(100*(csum/total), 1),
  ) %>% 
  ungroup() %>% 
  mutate(
    item = case_when(
      lag(item) == item  ~ NA_character_,
      TRUE ~ item
    ), 
    across(c(total_pct, valid_pct, valid_cum_pct), ~ format(., digits = 1, nsmall = 1)) 
  ) %>%
  select(item, value, label, n, total_pct, valid_pct, valid_cum_pct, total) %>% 
  rename(super_q = item, freq = n) %>% 
  mutate(across(super_q, ~ replace_na(., "")),
         sub_q = NA_character_,
         across(c(value, freq, total), ~ as.character(.))
  ) %>% 
  relocate(sub_q, .after = "super_q")

freq_table_all <- bind_rows(
  freq_table_super_sub_cols,
  freq_table_rhs_num_cols
)

text_cols_all <- bind_cols(
  lhs_cols,
  date_col,
  rhs_text_cols
)

write_xlsx(
  list(`text responses` = text_cols_all, `freq tables` = freq_table_all),
  here("OUTPUT-FILES/lms-report-survey-ados2-workshop-2021-04-16.xlsx")
)
```

<br>

###### COMMENTED SNIPPETS
Within `output`, there are two sets of columns to be processed for frequency table output: 

* `named_super_sub_r_cols`: columns containing the numerical responses to super-sub-ordinate question pairs;
* `rhs_num_cols`: other columns from the input containing numerical responses.

The code generates separate frequency tables for these two column sets, and then joins them together with other output in the final report.

In the first snippet, `freq_table_super_sub_cols` designates the frequency table for the super-sub-ordinate questions. We extract the names of the relevant columns into a character vector with `names(named_super_sub_r_cols)`, and segregate the columns for analysis by wrapping their names in `select(all_of())`. 

`tidyr::pivot_longer()` transforms the data object from wide to long (nested) format. The arguments to `pivot_longer()` include the tidyselect helper `everything()`, which indicates that all columns will be included in the transformation, and the names of the new destination columns for the input column names (`names_to`) and the input cell values (`values_to`). `pivot_longer()` returns a nested data frame with two columns, `item` and `value`. In this long object, the items and their respective response values are nested within each case (person row) of the input, running down the rows for one person and then repeating the same items for the next person, and so on.

`dplyr::count()` summarizes this object. Passing `item` and `value` as arguments groups the summary object by these two variables, such that a new column `n` provides the person count for each pairing of item and response value.
```{r freq, echo = 1:4, eval = FALSE}
```
Here are the first 10 rows of the summary table.
```
   item                                                              value     n

 1 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     3     7
 2 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     4     7
 3 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     5    20
 4 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     3     3
 5 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     4     7
 6 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     5    24
 7 Access/Setting/Overall_Experience:_Clarity_and_timeliness_of_inf…     3     6
 8 Access/Setting/Overall_Experience:_Clarity_and_timeliness_of_inf…     4     8
 9 Access/Setting/Overall_Experience:_Clarity_and_timeliness_of_inf…     5    20
10 Access/Setting/Overall_Experience:_Overall_educational_experience     3     3
```
The range of possible response values for the super-sub-ordinate questions is `1` to `5`. In the questions shown in the this example, no person chose responses `1` or `2`, so there are no rows corresponding to these two numerical responses. We must nevertheless report the person counts for `1` and `2` in the frequency table output. We use `tidyr::complete(value = 1:5)` to create rows for any numerical responses not chosen by person. `group_by(item)` ensures that missing rows are created separately for each unique value of `item`.
```{r freq, echo = 5:6, eval = FALSE}
```
The newly created rows appear in the next example. Each question now has five rows corresponding to the five possible response choices.
```
   item                                                              value     n

 1 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     1    NA
 2 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     2    NA
 3 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     3     7
 4 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     4     7
 5 Access/Setting/Overall_Experience:_Accessibility_of_platforms/ma…     5    20
 6 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     1    NA
 7 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     2    NA
 8 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     3     3
 9 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     4     7
10 Access/Setting/Overall_Experience:_Accessing_the_webinar_(e.g.,_…     5    24
```
The next snippet applies further modifications to the output. `arrange()` sorts the table in `desc()` order by `value`, retaining the existing group structure (`.by_group = TRUE`) so that sorting on response value is executed _within_ each item's five response-value rows. In the summary table, the substantive meaning of `NA` is `0` person responses. We use `tidyr::replace_na()` to recode `NA` to `0`, by passing a list of columns and replacement values (`list(n = 0)`). `mutate()` creates new columns (e.g., `total_pct`, `valid_pct`, etc.) that are needed for the final output. We wrap variable definitions in `round()` to apply required numerical formatting.
```{r freq, echo = 7:14, eval = FALSE}
```
In the current data object, super- and subordinate question pairs exist as a single long string in the `item` column. The frequency table output requires that each element of the pair reside in its own column. As described previously, we call call `tidyr::separate()` to divide up these long strings and send them to discrete destination columns. Here, the third argument specifies that the strings in `item` will be split on the string `:_` (which will be dropped), and the resulting substrings will be saved in the `"super_q"` and `"sub_q"` columns.
```{r freq, echo = 15:20, eval = FALSE}
```
In the current data object, `n` provides the person counts for each of the possible numerical responses in `value`. To make the frequency table output easier to interpret, we need to attach value lables to numerical responses. This task is complicated by the existence of several different sets of labels, across the super-ordinate question groups, corresponding to the five numerical response choices. The solution requires hard-coded response-label maps, but we can use `stringr` functions to make the code more concise.

The next snippet shows how this coding is accomplished within `mutate(case_when())`. We create a new column `label`, and populate it with values that correspond to certain combinations of super-ordinate questions and response values. These combinations are are expressed in predicates evaluated by `case_when()`. The complet predicate in the next snippet is `(str_detect(super_q, "Access") | str_detect(super_q, "Quality_of")) & value == 5`. Here, `stringr::str_detect()` returns `TRUE` when the string in `super_q` contains the substring `"Access"`. This substring identifies a certain super-ordinate question, allowing `str_detect()` to identify all rows containing that question without having to hard-code the entire long text of the question. The predicate in the snippet thus returns `TRUE` for _two_ super-ordinate questions that share the same response mappings (two calls of `str_detect()` joined with the conjunctive operator `|`), and codes `label` with `"Excellent"` in any rows, within either of the two super-ordinate questions, where `value == 5`.
```{r freq, echo = 21:23, eval = FALSE}
```
